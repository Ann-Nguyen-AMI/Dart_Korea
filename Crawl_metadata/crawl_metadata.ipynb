{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def wait(): time.sleep(0.5)\n",
    "\n",
    "class Crawler:\n",
    "    def __init__(self) -> None:\n",
    "        driver = Chrome()\n",
    "        driver.get(\"https://dart.fss.or.kr/dsab007/main.do?option=report\")\n",
    "\n",
    "        # Input report name\n",
    "        input_reportName = driver.find_element(By.ID, \"reportName\")\n",
    "        input_reportName.clear()\n",
    "        input_reportName.send_keys(\"사업보고서\")\n",
    "        wait()\n",
    "\n",
    "        # Click final report\n",
    "        final_report = driver.find_element(By.ID, \"finalReport\")\n",
    "        final_report.click()\n",
    "        wait()\n",
    "\n",
    "        # Set num line per page = 100\n",
    "        num_line_per_page = driver.find_element(By.ID, \"maxResultsCb\")\n",
    "        Select(num_line_per_page).select_by_value(\"100\")\n",
    "        wait()\n",
    "\n",
    "        #\n",
    "        self.driver = driver\n",
    "\n",
    "    def fill_startDate_endDate(self, startDate, endDate):\n",
    "        input_startDate = self.driver.find_element(By.ID, \"startDate\")\n",
    "        input_startDate.clear()\n",
    "        input_startDate.send_keys(startDate)\n",
    "        wait()\n",
    "\n",
    "        input_endDate = self.driver.find_element(By.ID, \"endDate\")\n",
    "        input_endDate.clear()\n",
    "        input_endDate.send_keys(endDate)\n",
    "        wait()\n",
    "\n",
    "        self.driver.find_element(By.CLASS_NAME, \"btnArea\").find_element(By.CLASS_NAME, \"btnSearch\").click()\n",
    "        wait()\n",
    "\n",
    "        self.wait_for_data()\n",
    "\n",
    "    def get_soup(self):\n",
    "        return BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "\n",
    "    def wait_for_data(self, first_index=1):\n",
    "        while True:\n",
    "            soup = self.get_soup()\n",
    "            table = soup.find(\"table\")\n",
    "            df = pd.read_html(StringIO(str(table)))[0]\n",
    "            if df.iloc[0,0] == first_index: return\n",
    "            wait()\n",
    "\n",
    "    def get_table(self):\n",
    "        soup = self.get_soup()\n",
    "        table = soup.find(\"table\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        list_tr = table.find(\"tbody\").find_all(\"tr\")\n",
    "        assert len(list_tr) == len(df)\n",
    "        list_popup_href = []\n",
    "        list_report_href = []\n",
    "        for tr in list_tr:\n",
    "            list_td = tr.find_all(\"td\")\n",
    "            assert len(list_td) == df.shape[1]\n",
    "\n",
    "            popup_href = list_td[1].find(\"a\")[\"href\"]\n",
    "            list_popup_href.append(popup_href)\n",
    "\n",
    "            report_href = list_td[2].find(\"a\")[\"href\"]\n",
    "            list_report_href.append(report_href)\n",
    "\n",
    "        df[\"popup_href\"] = list_popup_href\n",
    "        df[\"report_href\"] = report_href\n",
    "\n",
    "        assert df[\"popup_href\"].str.startswith(\"javascript:openCorpInfoNew('\").all()\n",
    "        assert df[\"popup_href\"].str.endswith(\"', 'winCorpInfo', '/dsae001/selectPopup.ax');\").all()\n",
    "        df[\"popup_href\"] = df[\"popup_href\"].str[len(\"javascript:openCorpInfoNew('\"):-len(\"', 'winCorpInfo', '/dsae001/selectPopup.ax');\")]\n",
    "\n",
    "        assert df[\"report_href\"].str.startswith(\"/dsaf001/main.do?rcpNo=\").all()\n",
    "        df[\"report_href\"] = df[\"report_href\"].str[len(\"/dsaf001/main.do?rcpNo=\"):]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def go_next_page(self, page):\n",
    "        if page == 1: return\n",
    "\n",
    "        div = self.driver.find_element(By.CLASS_NAME, \"pageSkip\")\n",
    "        list_li = div.find_element(By.TAG_NAME, \"ul\").find_elements(By.TAG_NAME, \"li\")\n",
    "        if page % 10 == 1: list_li[-2].find_element(By.TAG_NAME, \"a\").click()\n",
    "        else:\n",
    "            button_id = (page - 1) % 10 + 2\n",
    "            list_li[button_id].find_element(By.TAG_NAME, \"a\").click()\n",
    "\n",
    "        first_index = 1 + 100 * (page - 1)\n",
    "        self.wait_for_data(first_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = Crawler()\n",
    "for iii in range(8):\n",
    "    startDate = f\"{2021-3*iii}0411\"\n",
    "    endDate = f\"{2024-3*iii}0410\"\n",
    "    crawler.fill_startDate_endDate(startDate, endDate)\n",
    "    soup = crawler.get_soup()\n",
    "    pageInfo = soup.find(\"div\", attrs={\"class\":\"pageInfo\"})\n",
    "    temp = \"\".join(pageInfo.text.split()).split(\"][\")\n",
    "    total_page = int(temp[0].split(\"/\")[1])\n",
    "    total_line = int(re.findall(r\"\\d+\", \"\".join(temp[1].split(\",\")))[0])\n",
    "    total_df = None\n",
    "    for page in tqdm(range(1, total_page+1)):\n",
    "        crawler.go_next_page(page)\n",
    "        df = crawler.get_table()\n",
    "        try:\n",
    "            total_df = pd.concat([total_df, df], ignore_index=True)\n",
    "        except:\n",
    "            total_df = df.copy()\n",
    "    \n",
    "    total_df.to_csv(f\"{iii}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
